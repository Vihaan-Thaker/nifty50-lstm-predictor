{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0047d9c-3edb-49f2-b74a-cee86003be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from datetime import datetime , timedelta\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from ta.momentum import RSIIndicator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a75401-5e40-4193-94c3-50ea5737f46e",
   "metadata": {},
   "source": [
    "#### Firstly we get the stickers for NIFTY50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20b8d97-7715-4b93-8891-ea326a3a0398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BEL.NS', 'BHARTIARTL.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'ETERNAL.NS', 'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HINDALCO.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'INDIGO.NS', 'INFY.NS', 'ITC.NS', 'JIOFIN.NS', 'JSWSTEEL.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'NESTLEIND.NS', 'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SHRIRAMFIN.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TCS.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TECHM.NS', 'TITAN.NS', 'TRENT.NS', 'ULTRACEMCO.NS', 'WIPRO.NS']\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "url = 'https://en.wikipedia.org/wiki/NIFTY_50'\n",
    "\n",
    "# Add headers to avoid 403 error\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetch the page content with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "table = pd.read_html(StringIO(response.text))\n",
    "\n",
    "nifty50_df = table[1]  # Table 1 contains the NIFTY 50 companies\n",
    "nifty50_tickers = nifty50_df['Symbol'].tolist()\n",
    "nifty50_tickers = [ticker + '.NS' for ticker in nifty50_tickers]\n",
    "print(nifty50_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316c404-240d-4560-865c-91d32fca3da7",
   "metadata": {},
   "source": [
    "#### Importing all the libraries required to build the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fddd87e-0200-4eef-872b-c89746249a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #This is required to make the Neural Network layer by layer\n",
    "from tensorflow.keras.layers import * #Used to import LSTM layer , Dense ( fully connected layer ) , Dropout ( Regularization to prevent overfitting)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint #Automatically saves the best model even if later epochs overfit or degrade\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam #Used to adjust the model weights during training\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c027db9-d358-4e69-b541-88dc63aed83a",
   "metadata": {},
   "source": [
    "#### Below Function is called inside the train_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3729c07-b8bf-4ddf-8f05-eb6a852a4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(30, 6)))  # 6 input features\n",
    "\n",
    "    model.add(LSTM(units=hp.Int('lstm_units', min_value=32, max_value=128, step=16)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', 0.0, 0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', 8, 64, step=8), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e6049-ff48-4191-861e-753a8ea6e856",
   "metadata": {},
   "source": [
    "#### The below function is to get the ticker data for the particular ticker symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f3f5d2c-ed48-41f0-b366-bcebe86c6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(symbol , start_date , end_date):\n",
    "    buffer_start_date = start_date - timedelta(days=300)\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    data = ticker.history(start = buffer_start_date , end = end_date)\n",
    "\n",
    "    nifty_ticker = yf.Ticker('^NSEI')\n",
    "    nifty_data = nifty_ticker.history(start = start_date , end = end_date)\n",
    "    \n",
    "    data['Return'] = data['Close'].pct_change()\n",
    "    data['MA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['MA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['RSI'] = RSIIndicator(close=data['Close'],window=14).rsi()\n",
    "    data['Volatility'] = data['Return'].rolling(window=14).std()\n",
    "    \n",
    "    data = data.loc[pd.to_datetime(start_date).tz_localize('UTC'):]\n",
    "    nifty_data['nifty_returns'] = nifty_data['Close'].pct_change()\n",
    "    data = data.join(nifty_data['nifty_returns'])\n",
    "    \n",
    "    data[['Volatility','MA_50','MA_200','RSI']] = scaler.fit_transform(data[['Volatility','MA_50','MA_200','RSI']])\n",
    "    return data[['Return','Volatility','MA_50','MA_200','RSI','nifty_returns']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c265278-5d33-478e-9ee5-89b50387a624",
   "metadata": {},
   "source": [
    "#### The Below function is just to convert a dataframe to a numpy array so it can be manipulated more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "011eec7e-9274-4507-9409-73d4ab22a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_np(X , y):\n",
    "    X_np = np.array([df.values for df in X])\n",
    "    y_np = np.array(y)\n",
    "    return X_np , y_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c9710-411e-4b22-a0e7-73970a32d304",
   "metadata": {},
   "source": [
    "#### The Below function is to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e51938f-5ff1-44ec-b4b3-03800dc1e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(symbol, train_input, train_label, validation_input, validation_labels):\n",
    "    print(f'Searching for best hyper-params for {symbol} model')\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=20,\n",
    "        executions_per_trial=1,\n",
    "        directory='lstm_tuning',\n",
    "        project_name=f'nifty_predict_{symbol}'  # make it per-symbol to avoid overwrite\n",
    "    )\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    tuner.search(train_input, train_label,\n",
    "                 validation_data=(validation_input, validation_labels),\n",
    "                 epochs=10)\n",
    "\n",
    "    # Get best model\n",
    "    model1 = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    print(f'Hyper-Params for best model of {symbol} have been found')\n",
    "    # Save best weights\n",
    "    cp = ModelCheckpoint(f'model1_{symbol}/model.keras', save_best_only=True)\n",
    "    model1.fit(train_input, train_label,\n",
    "               validation_data=(validation_input, validation_labels),\n",
    "               epochs=10, callbacks=[cp])\n",
    "\n",
    "    # Reload best version and evaluate\n",
    "    model1 = load_model(f'model1_{symbol}/model.keras')\n",
    "    val_predictions = model1.predict(validation_input).flatten()\n",
    "    predicted_labels = (val_predictions > 0.5).astype(int)\n",
    "    accuracy = np.mean(predicted_labels == validation_labels)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1664e-45a0-41c9-a987-67831b4840ff",
   "metadata": {},
   "source": [
    "#### Below we call all the required functions and store the accuracies for each model in the respective dictionary\n",
    "#### Note that I have excluded a few companies while going through the tickers as they were having a problem while executing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aee7c5a-6056-4aad-a18d-f9af8b4fa971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered the Loop for ADANIENT.NS\n",
      "Validation Data Collected for ADANIENT.NS\n",
      "Training Data Collected for ADANIENT.NS\n",
      "Searching for best hyper-params for ADANIENT.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ADANIENT.NS/tuner0.json\n",
      "Hyper-Params for best model of ADANIENT.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4907 - loss: 0.6914 - val_accuracy: 0.6316 - val_loss: 0.6771\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5679 - loss: 0.6822 - val_accuracy: 0.6316 - val_loss: 0.6752\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6900 - loss: 0.6616 - val_accuracy: 0.6316 - val_loss: 0.6727\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6128 - loss: 0.6609 - val_accuracy: 0.6316 - val_loss: 0.6701\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7317 - loss: 0.6462 - val_accuracy: 0.6316 - val_loss: 0.6672\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7223 - loss: 0.6230 - val_accuracy: 0.6316 - val_loss: 0.6643\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7015 - loss: 0.6239 - val_accuracy: 0.6316 - val_loss: 0.6612\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7453 - loss: 0.6076 - val_accuracy: 0.6316 - val_loss: 0.6580\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7683 - loss: 0.5945 - val_accuracy: 0.6316 - val_loss: 0.6545\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7234 - loss: 0.5983 - val_accuracy: 0.6316 - val_loss: 0.6518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for ADANIENT.NS\n",
      "Entered the Loop for ADANIPORTS.NS\n",
      "Validation Data Collected for ADANIPORTS.NS\n",
      "Training Data Collected for ADANIPORTS.NS\n",
      "Searching for best hyper-params for ADANIPORTS.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ADANIPORTS.NS/tuner0.json\n",
      "Hyper-Params for best model of ADANIPORTS.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5323 - loss: 0.6899 - val_accuracy: 0.5789 - val_loss: 0.6798\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6117 - loss: 0.6950 - val_accuracy: 0.5789 - val_loss: 0.6793\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5427 - loss: 0.6910 - val_accuracy: 0.5789 - val_loss: 0.6788\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6336 - loss: 0.6881 - val_accuracy: 0.5789 - val_loss: 0.6781\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5241 - loss: 0.6890 - val_accuracy: 0.5789 - val_loss: 0.6783\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6419 - loss: 0.6776 - val_accuracy: 0.5789 - val_loss: 0.6786\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4896 - loss: 0.6928 - val_accuracy: 0.5789 - val_loss: 0.6787\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6325 - loss: 0.6765 - val_accuracy: 0.5789 - val_loss: 0.6788\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6232 - loss: 0.6766 - val_accuracy: 0.5789 - val_loss: 0.6789\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5887 - loss: 0.6804 - val_accuracy: 0.5789 - val_loss: 0.6789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for ADANIPORTS.NS\n",
      "Entered the Loop for APOLLOHOSP.NS\n",
      "Validation Data Collected for APOLLOHOSP.NS\n",
      "Training Data Collected for APOLLOHOSP.NS\n",
      "Searching for best hyper-params for APOLLOHOSP.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_APOLLOHOSP.NS/tuner0.json\n",
      "Hyper-Params for best model of APOLLOHOSP.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6221 - loss: 0.6637 - val_accuracy: 0.5789 - val_loss: 0.6738\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6315 - loss: 0.6136 - val_accuracy: 0.3158 - val_loss: 0.7605\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7525 - loss: 0.6004 - val_accuracy: 0.2632 - val_loss: 0.7600\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6451 - loss: 0.6227 - val_accuracy: 0.3158 - val_loss: 0.8070\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6681 - loss: 0.6100 - val_accuracy: 0.3158 - val_loss: 0.8263\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7295 - loss: 0.5567 - val_accuracy: 0.2632 - val_loss: 0.8271\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7108 - loss: 0.5946 - val_accuracy: 0.2632 - val_loss: 0.7892\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6785 - loss: 0.6111 - val_accuracy: 0.3158 - val_loss: 0.7865\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6994 - loss: 0.5647 - val_accuracy: 0.2632 - val_loss: 0.8340\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7213 - loss: 0.5714 - val_accuracy: 0.1579 - val_loss: 0.8634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for APOLLOHOSP.NS\n",
      "Entered the Loop for ASIANPAINT.NS\n",
      "Validation Data Collected for ASIANPAINT.NS\n",
      "Training Data Collected for ASIANPAINT.NS\n",
      "Searching for best hyper-params for ASIANPAINT.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ASIANPAINT.NS/tuner0.json\n",
      "Hyper-Params for best model of ASIANPAINT.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5334 - loss: 0.6908 - val_accuracy: 0.3684 - val_loss: 0.6984\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7223 - loss: 0.6686 - val_accuracy: 0.5263 - val_loss: 0.6957\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5920 - loss: 0.6750 - val_accuracy: 0.5789 - val_loss: 0.6950\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6013 - loss: 0.6648 - val_accuracy: 0.6316 - val_loss: 0.6940\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7536 - loss: 0.6495 - val_accuracy: 0.5789 - val_loss: 0.6915\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7328 - loss: 0.6367 - val_accuracy: 0.6316 - val_loss: 0.6892\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7202 - loss: 0.6271 - val_accuracy: 0.6316 - val_loss: 0.6880\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6117 - loss: 0.6430 - val_accuracy: 0.4737 - val_loss: 0.6853\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6347 - loss: 0.6352 - val_accuracy: 0.4737 - val_loss: 0.6837\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6659 - loss: 0.6143 - val_accuracy: 0.4737 - val_loss: 0.6820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Loop done for ASIANPAINT.NS\n",
      "Entered the Loop for AXISBANK.NS\n",
      "Validation Data Collected for AXISBANK.NS\n",
      "Training Data Collected for AXISBANK.NS\n",
      "Searching for best hyper-params for AXISBANK.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_AXISBANK.NS/tuner0.json\n",
      "Hyper-Params for best model of AXISBANK.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5876 - loss: 0.6897 - val_accuracy: 0.6316 - val_loss: 0.6857\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5323 - loss: 0.6822 - val_accuracy: 0.6316 - val_loss: 0.6863\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5449 - loss: 0.6820 - val_accuracy: 0.6316 - val_loss: 0.6869\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5334 - loss: 0.6877 - val_accuracy: 0.6316 - val_loss: 0.6864\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6002 - loss: 0.6569 - val_accuracy: 0.6316 - val_loss: 0.6871\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5356 - loss: 0.6779 - val_accuracy: 0.6316 - val_loss: 0.6881\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5647 - loss: 0.6550 - val_accuracy: 0.6316 - val_loss: 0.6880\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5657 - loss: 0.6887 - val_accuracy: 0.6316 - val_loss: 0.6886\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6451 - loss: 0.6652 - val_accuracy: 0.6316 - val_loss: 0.6889\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6670 - loss: 0.6434 - val_accuracy: 0.6316 - val_loss: 0.6897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for AXISBANK.NS\n",
      "Entered the Loop for BAJAJ-AUTO.NS\n",
      "Validation Data Collected for BAJAJ-AUTO.NS\n",
      "Training Data Collected for BAJAJ-AUTO.NS\n",
      "Searching for best hyper-params for BAJAJ-AUTO.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_BAJAJ-AUTO.NS/tuner0.json\n",
      "Hyper-Params for best model of BAJAJ-AUTO.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5679 - loss: 0.6747 - val_accuracy: 0.3684 - val_loss: 0.7033\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5668 - loss: 0.6772 - val_accuracy: 0.3684 - val_loss: 0.7105\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5783 - loss: 0.6590 - val_accuracy: 0.3684 - val_loss: 0.7109\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6649 - loss: 0.6428 - val_accuracy: 0.3684 - val_loss: 0.7153\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5898 - loss: 0.6533 - val_accuracy: 0.4211 - val_loss: 0.7057\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7098 - loss: 0.6405 - val_accuracy: 0.5263 - val_loss: 0.6978\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6210 - loss: 0.6345 - val_accuracy: 0.4737 - val_loss: 0.7028\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6659 - loss: 0.6395 - val_accuracy: 0.5263 - val_loss: 0.6959\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6325 - loss: 0.6264 - val_accuracy: 0.5789 - val_loss: 0.6941\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6649 - loss: 0.6256 - val_accuracy: 0.5789 - val_loss: 0.6977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for BAJAJ-AUTO.NS\n",
      "Entered the Loop for BAJFINANCE.NS\n",
      "Validation Data Collected for BAJFINANCE.NS\n",
      "Training Data Collected for BAJFINANCE.NS\n",
      "Searching for best hyper-params for BAJFINANCE.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_BAJFINANCE.NS/tuner0.json\n",
      "Hyper-Params for best model of BAJFINANCE.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4343 - loss: 0.7279 - val_accuracy: 0.4737 - val_loss: 0.7041\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6555 - loss: 0.6692 - val_accuracy: 0.4737 - val_loss: 0.7026\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7087 - loss: 0.6608 - val_accuracy: 0.4737 - val_loss: 0.7100\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6545 - loss: 0.6616 - val_accuracy: 0.4737 - val_loss: 0.7103\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6347 - loss: 0.6623 - val_accuracy: 0.4737 - val_loss: 0.7192\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7015 - loss: 0.6398 - val_accuracy: 0.4737 - val_loss: 0.7209\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6232 - loss: 0.6444 - val_accuracy: 0.4737 - val_loss: 0.7312\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7004 - loss: 0.6170 - val_accuracy: 0.4737 - val_loss: 0.7407\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7421 - loss: 0.6056 - val_accuracy: 0.4737 - val_loss: 0.7525\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7119 - loss: 0.6151 - val_accuracy: 0.4737 - val_loss: 0.7586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for BAJFINANCE.NS\n",
      "Entered the Loop for BAJAJFINSV.NS\n",
      "Validation Data Collected for BAJAJFINSV.NS\n",
      "Training Data Collected for BAJAJFINSV.NS\n",
      "Searching for best hyper-params for BAJAJFINSV.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_BAJAJFINSV.NS/tuner0.json\n",
      "Hyper-Params for best model of BAJAJFINSV.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4009 - loss: 0.7012 - val_accuracy: 0.5789 - val_loss: 0.6923\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5553 - loss: 0.6809 - val_accuracy: 0.5789 - val_loss: 0.7007\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4770 - loss: 0.6844 - val_accuracy: 0.4211 - val_loss: 0.7096\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5783 - loss: 0.6762 - val_accuracy: 0.4211 - val_loss: 0.7086\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6221 - loss: 0.6554 - val_accuracy: 0.4211 - val_loss: 0.7087\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6764 - loss: 0.6523 - val_accuracy: 0.4211 - val_loss: 0.7072\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6889 - loss: 0.6512 - val_accuracy: 0.4211 - val_loss: 0.7099\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6659 - loss: 0.6416 - val_accuracy: 0.4211 - val_loss: 0.7200\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7223 - loss: 0.6327 - val_accuracy: 0.4211 - val_loss: 0.7278\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7223 - loss: 0.6245 - val_accuracy: 0.4211 - val_loss: 0.7324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for BAJAJFINSV.NS\n",
      "Entered the Loop for BEL.NS\n",
      "Validation Data Collected for BEL.NS\n",
      "Training Data Collected for BEL.NS\n",
      "Searching for best hyper-params for BEL.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_BEL.NS/tuner0.json\n",
      "Hyper-Params for best model of BEL.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5876 - loss: 0.6939 - val_accuracy: 0.7368 - val_loss: 0.6703\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5460 - loss: 0.6876 - val_accuracy: 0.7368 - val_loss: 0.6689\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6868 - loss: 0.6608 - val_accuracy: 0.7368 - val_loss: 0.6684\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6649 - loss: 0.6531 - val_accuracy: 0.7368 - val_loss: 0.6683\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6659 - loss: 0.6498 - val_accuracy: 0.7368 - val_loss: 0.6671\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6232 - loss: 0.6534 - val_accuracy: 0.7368 - val_loss: 0.6666\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6315 - loss: 0.6276 - val_accuracy: 0.7368 - val_loss: 0.6665\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6868 - loss: 0.6276 - val_accuracy: 0.7368 - val_loss: 0.6657\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6221 - loss: 0.6415 - val_accuracy: 0.6842 - val_loss: 0.6664\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6451 - loss: 0.6341 - val_accuracy: 0.6842 - val_loss: 0.6677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for BEL.NS\n",
      "Entered the Loop for BHARTIARTL.NS\n",
      "Validation Data Collected for BHARTIARTL.NS\n",
      "Training Data Collected for BHARTIARTL.NS\n",
      "Searching for best hyper-params for BHARTIARTL.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_BHARTIARTL.NS/tuner0.json\n",
      "Hyper-Params for best model of BHARTIARTL.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3581 - loss: 0.7181 - val_accuracy: 0.4737 - val_loss: 0.6964\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6419 - loss: 0.6654 - val_accuracy: 0.4211 - val_loss: 0.6937\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6210 - loss: 0.6549 - val_accuracy: 0.3158 - val_loss: 0.6897\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6440 - loss: 0.6643 - val_accuracy: 0.4737 - val_loss: 0.6899\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6408 - loss: 0.6501 - val_accuracy: 0.3684 - val_loss: 0.6918\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5690 - loss: 0.6503 - val_accuracy: 0.3684 - val_loss: 0.6928\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5898 - loss: 0.6654 - val_accuracy: 0.4211 - val_loss: 0.6947\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5761 - loss: 0.6759 - val_accuracy: 0.4211 - val_loss: 0.6968\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6440 - loss: 0.6442 - val_accuracy: 0.3684 - val_loss: 0.6951\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6002 - loss: 0.6437 - val_accuracy: 0.3684 - val_loss: 0.6962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for BHARTIARTL.NS\n",
      "Entered the Loop for CIPLA.NS\n",
      "Validation Data Collected for CIPLA.NS\n",
      "Training Data Collected for CIPLA.NS\n",
      "Searching for best hyper-params for CIPLA.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_CIPLA.NS/tuner0.json\n",
      "Hyper-Params for best model of CIPLA.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5345 - loss: 0.6957 - val_accuracy: 0.6316 - val_loss: 0.6836\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6128 - loss: 0.6679 - val_accuracy: 0.6316 - val_loss: 0.6815\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6117 - loss: 0.6525 - val_accuracy: 0.6316 - val_loss: 0.6751\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6911 - loss: 0.6492 - val_accuracy: 0.6316 - val_loss: 0.6720\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6670 - loss: 0.6393 - val_accuracy: 0.6316 - val_loss: 0.6699\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6221 - loss: 0.6596 - val_accuracy: 0.6316 - val_loss: 0.6679\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6785 - loss: 0.6579 - val_accuracy: 0.6316 - val_loss: 0.6655\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6013 - loss: 0.6421 - val_accuracy: 0.6316 - val_loss: 0.6642\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6879 - loss: 0.6213 - val_accuracy: 0.6316 - val_loss: 0.6622\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6545 - loss: 0.6357 - val_accuracy: 0.6316 - val_loss: 0.6614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for CIPLA.NS\n",
      "Entered the Loop for COALINDIA.NS\n",
      "Validation Data Collected for COALINDIA.NS\n",
      "Training Data Collected for COALINDIA.NS\n",
      "Searching for best hyper-params for COALINDIA.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_COALINDIA.NS/tuner0.json\n",
      "Hyper-Params for best model of COALINDIA.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6868 - loss: 0.6865 - val_accuracy: 0.7895 - val_loss: 0.6563\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6117 - loss: 0.6794 - val_accuracy: 0.7895 - val_loss: 0.6549\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6440 - loss: 0.6701 - val_accuracy: 0.7368 - val_loss: 0.6535\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6002 - loss: 0.6659 - val_accuracy: 0.7368 - val_loss: 0.6530\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6106 - loss: 0.6622 - val_accuracy: 0.7368 - val_loss: 0.6528\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6106 - loss: 0.6584 - val_accuracy: 0.7368 - val_loss: 0.6534\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6315 - loss: 0.6485 - val_accuracy: 0.7368 - val_loss: 0.6546\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5690 - loss: 0.6600 - val_accuracy: 0.7368 - val_loss: 0.6563\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6002 - loss: 0.6492 - val_accuracy: 0.7368 - val_loss: 0.6579\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6106 - loss: 0.6370 - val_accuracy: 0.7368 - val_loss: 0.6586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for COALINDIA.NS\n",
      "Entered the Loop for DRREDDY.NS\n",
      "Validation Data Collected for DRREDDY.NS\n",
      "Training Data Collected for DRREDDY.NS\n",
      "Searching for best hyper-params for DRREDDY.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_DRREDDY.NS/tuner0.json\n",
      "Hyper-Params for best model of DRREDDY.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5438 - loss: 0.7015 - val_accuracy: 0.4737 - val_loss: 0.6995\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5438 - loss: 0.6851 - val_accuracy: 0.4737 - val_loss: 0.6976\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5230 - loss: 0.6780 - val_accuracy: 0.3684 - val_loss: 0.6971\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5542 - loss: 0.6722 - val_accuracy: 0.3684 - val_loss: 0.6964\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6764 - loss: 0.6632 - val_accuracy: 0.3684 - val_loss: 0.6947\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7651 - loss: 0.6603 - val_accuracy: 0.3684 - val_loss: 0.6956\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6983 - loss: 0.6589 - val_accuracy: 0.3684 - val_loss: 0.6965\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7328 - loss: 0.6560 - val_accuracy: 0.3684 - val_loss: 0.6966\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7317 - loss: 0.6534 - val_accuracy: 0.3684 - val_loss: 0.6965\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6774 - loss: 0.6527 - val_accuracy: 0.3684 - val_loss: 0.6961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Loop done for DRREDDY.NS\n",
      "Entered the Loop for GRASIM.NS\n",
      "Validation Data Collected for GRASIM.NS\n",
      "Training Data Collected for GRASIM.NS\n",
      "Searching for best hyper-params for GRASIM.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_GRASIM.NS/tuner0.json\n",
      "Hyper-Params for best model of GRASIM.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6221 - loss: 0.6863 - val_accuracy: 0.5263 - val_loss: 0.7586\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7004 - loss: 0.6578 - val_accuracy: 0.5263 - val_loss: 0.7766\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6566 - loss: 0.6241 - val_accuracy: 0.5263 - val_loss: 0.7889\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6566 - loss: 0.6187 - val_accuracy: 0.5263 - val_loss: 0.7964\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6117 - loss: 0.6357 - val_accuracy: 0.5263 - val_loss: 0.8044\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7004 - loss: 0.5987 - val_accuracy: 0.5263 - val_loss: 0.8076\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7026 - loss: 0.6066 - val_accuracy: 0.5263 - val_loss: 0.8218\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7755 - loss: 0.5639 - val_accuracy: 0.5263 - val_loss: 0.7898\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7108 - loss: 0.5762 - val_accuracy: 0.5263 - val_loss: 0.7638\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7015 - loss: 0.5978 - val_accuracy: 0.5263 - val_loss: 0.7360\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for GRASIM.NS\n",
      "Entered the Loop for HCLTECH.NS\n",
      "Validation Data Collected for HCLTECH.NS\n",
      "Training Data Collected for HCLTECH.NS\n",
      "Searching for best hyper-params for HCLTECH.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_HCLTECH.NS/tuner0.json\n",
      "Hyper-Params for best model of HCLTECH.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5866 - loss: 0.6925 - val_accuracy: 0.8421 - val_loss: 0.6271\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5876 - loss: 0.6831 - val_accuracy: 0.8421 - val_loss: 0.6172\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5668 - loss: 0.6848 - val_accuracy: 0.8421 - val_loss: 0.6084\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5668 - loss: 0.6791 - val_accuracy: 0.8421 - val_loss: 0.6022\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5668 - loss: 0.6771 - val_accuracy: 0.8421 - val_loss: 0.5993\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5876 - loss: 0.6699 - val_accuracy: 0.8421 - val_loss: 0.5997\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5668 - loss: 0.6728 - val_accuracy: 0.8421 - val_loss: 0.6016\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5772 - loss: 0.6685 - val_accuracy: 0.8421 - val_loss: 0.6042\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5772 - loss: 0.6684 - val_accuracy: 0.8421 - val_loss: 0.6073\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5876 - loss: 0.6597 - val_accuracy: 0.8421 - val_loss: 0.6102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for HCLTECH.NS\n",
      "Entered the Loop for HDFCBANK.NS\n",
      "Validation Data Collected for HDFCBANK.NS\n",
      "Training Data Collected for HDFCBANK.NS\n",
      "Searching for best hyper-params for HDFCBANK.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_HDFCBANK.NS/tuner0.json\n",
      "Hyper-Params for best model of HDFCBANK.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5323 - loss: 0.6855 - val_accuracy: 0.1579 - val_loss: 0.7479\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5991 - loss: 0.6740 - val_accuracy: 0.1579 - val_loss: 0.7686\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5876 - loss: 0.6623 - val_accuracy: 0.1579 - val_loss: 0.7828\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5876 - loss: 0.6617 - val_accuracy: 0.1579 - val_loss: 0.7990\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 0.6560 - val_accuracy: 0.1579 - val_loss: 0.8070\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5761 - loss: 0.6489 - val_accuracy: 0.1579 - val_loss: 0.8119\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 0.6558 - val_accuracy: 0.1579 - val_loss: 0.8207\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6002 - loss: 0.6498 - val_accuracy: 0.1579 - val_loss: 0.8328\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6555 - loss: 0.6479 - val_accuracy: 0.1579 - val_loss: 0.8389\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6336 - loss: 0.6532 - val_accuracy: 0.1579 - val_loss: 0.8478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Loop done for HDFCBANK.NS\n",
      "Entered the Loop for HDFCLIFE.NS\n",
      "Validation Data Collected for HDFCLIFE.NS\n",
      "Training Data Collected for HDFCLIFE.NS\n",
      "Searching for best hyper-params for HDFCLIFE.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_HDFCLIFE.NS/tuner0.json\n",
      "Hyper-Params for best model of HDFCLIFE.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5104 - loss: 0.6939 - val_accuracy: 0.1579 - val_loss: 0.7101\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5772 - loss: 0.6754 - val_accuracy: 0.2632 - val_loss: 0.7029\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5679 - loss: 0.6808 - val_accuracy: 0.4737 - val_loss: 0.6967\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6555 - loss: 0.6522 - val_accuracy: 0.7368 - val_loss: 0.6907\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6221 - loss: 0.6477 - val_accuracy: 0.7368 - val_loss: 0.6849\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6106 - loss: 0.6537 - val_accuracy: 0.7368 - val_loss: 0.6781\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6002 - loss: 0.6308 - val_accuracy: 0.7368 - val_loss: 0.6706\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6096 - loss: 0.6218 - val_accuracy: 0.7368 - val_loss: 0.6623\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6868 - loss: 0.5994 - val_accuracy: 0.7368 - val_loss: 0.6536\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7108 - loss: 0.6086 - val_accuracy: 0.7368 - val_loss: 0.6454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for HDFCLIFE.NS\n",
      "Entered the Loop for HINDALCO.NS\n",
      "Validation Data Collected for HINDALCO.NS\n",
      "Training Data Collected for HINDALCO.NS\n",
      "Searching for best hyper-params for HINDALCO.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_HINDALCO.NS/tuner0.json\n",
      "Hyper-Params for best model of HINDALCO.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5334 - loss: 0.6772 - val_accuracy: 0.4737 - val_loss: 0.6936\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7328 - loss: 0.6451 - val_accuracy: 0.4737 - val_loss: 0.6928\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7443 - loss: 0.6234 - val_accuracy: 0.4737 - val_loss: 0.6928\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7223 - loss: 0.6141 - val_accuracy: 0.4737 - val_loss: 0.6922\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6900 - loss: 0.6059 - val_accuracy: 0.4737 - val_loss: 0.6925\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6983 - loss: 0.5934 - val_accuracy: 0.4737 - val_loss: 0.6918\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7004 - loss: 0.5902 - val_accuracy: 0.5263 - val_loss: 0.6917\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6659 - loss: 0.5648 - val_accuracy: 0.5263 - val_loss: 0.6922\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6785 - loss: 0.5918 - val_accuracy: 0.5263 - val_loss: 0.6918\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6681 - loss: 0.6033 - val_accuracy: 0.5263 - val_loss: 0.6920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Loop done for HINDALCO.NS\n",
      "Entered the Loop for HINDUNILVR.NS\n",
      "Validation Data Collected for HINDUNILVR.NS\n",
      "Training Data Collected for HINDUNILVR.NS\n",
      "Searching for best hyper-params for HINDUNILVR.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_HINDUNILVR.NS/tuner0.json\n",
      "Hyper-Params for best model of HINDUNILVR.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6106 - loss: 0.6709 - val_accuracy: 0.2632 - val_loss: 0.7373\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6534 - loss: 0.6556 - val_accuracy: 0.2632 - val_loss: 0.7393\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6545 - loss: 0.6404 - val_accuracy: 0.2632 - val_loss: 0.7416\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6545 - loss: 0.6321 - val_accuracy: 0.2632 - val_loss: 0.7425\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6534 - loss: 0.6269 - val_accuracy: 0.2632 - val_loss: 0.7437\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6232 - loss: 0.6402 - val_accuracy: 0.2632 - val_loss: 0.7442\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6440 - loss: 0.6209 - val_accuracy: 0.2632 - val_loss: 0.7438\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 0.6263 - val_accuracy: 0.2632 - val_loss: 0.7419\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6555 - loss: 0.6332 - val_accuracy: 0.2632 - val_loss: 0.7405\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 0.6374 - val_accuracy: 0.2632 - val_loss: 0.7433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for HINDUNILVR.NS\n",
      "Entered the Loop for ICICIBANK.NS\n",
      "Validation Data Collected for ICICIBANK.NS\n",
      "Training Data Collected for ICICIBANK.NS\n",
      "Searching for best hyper-params for ICICIBANK.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ICICIBANK.NS/tuner0.json\n",
      "Hyper-Params for best model of ICICIBANK.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5093 - loss: 0.7005 - val_accuracy: 0.3158 - val_loss: 0.7240\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5230 - loss: 0.6894 - val_accuracy: 0.3158 - val_loss: 0.7267\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5323 - loss: 0.6874 - val_accuracy: 0.3158 - val_loss: 0.7286\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6200 - loss: 0.6852 - val_accuracy: 0.3158 - val_loss: 0.7318\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4874 - loss: 0.6923 - val_accuracy: 0.3158 - val_loss: 0.7342\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5542 - loss: 0.6859 - val_accuracy: 0.3158 - val_loss: 0.7357\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5679 - loss: 0.6835 - val_accuracy: 0.3158 - val_loss: 0.7379\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5585 - loss: 0.6864 - val_accuracy: 0.3158 - val_loss: 0.7406\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5981 - loss: 0.6790 - val_accuracy: 0.3158 - val_loss: 0.7426\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5887 - loss: 0.6805 - val_accuracy: 0.3158 - val_loss: 0.7452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Loop done for ICICIBANK.NS\n",
      "Entered the Loop for INDIGO.NS\n",
      "Validation Data Collected for INDIGO.NS\n",
      "Training Data Collected for INDIGO.NS\n",
      "Searching for best hyper-params for INDIGO.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_INDIGO.NS/tuner0.json\n",
      "Hyper-Params for best model of INDIGO.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5970 - loss: 0.6858 - val_accuracy: 0.6316 - val_loss: 0.6775\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6096 - loss: 0.6773 - val_accuracy: 0.5789 - val_loss: 0.6829\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6221 - loss: 0.6712 - val_accuracy: 0.3684 - val_loss: 0.6940\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6972 - loss: 0.6609 - val_accuracy: 0.3684 - val_loss: 0.7064\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6889 - loss: 0.6578 - val_accuracy: 0.3684 - val_loss: 0.7156\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6243 - loss: 0.6596 - val_accuracy: 0.3684 - val_loss: 0.7215\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6555 - loss: 0.6502 - val_accuracy: 0.3684 - val_loss: 0.7284\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6451 - loss: 0.6513 - val_accuracy: 0.3684 - val_loss: 0.7312\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6451 - loss: 0.6445 - val_accuracy: 0.3684 - val_loss: 0.7352\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6659 - loss: 0.6416 - val_accuracy: 0.3684 - val_loss: 0.7387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for INDIGO.NS\n",
      "Entered the Loop for INFY.NS\n",
      "Validation Data Collected for INFY.NS\n",
      "Training Data Collected for INFY.NS\n",
      "Searching for best hyper-params for INFY.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_INFY.NS/tuner0.json\n",
      "Hyper-Params for best model of INFY.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5083 - loss: 0.7284 - val_accuracy: 0.3158 - val_loss: 0.7796\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5668 - loss: 0.7035 - val_accuracy: 0.3158 - val_loss: 0.7670\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6304 - loss: 0.6847 - val_accuracy: 0.3158 - val_loss: 0.7558\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5887 - loss: 0.6853 - val_accuracy: 0.3158 - val_loss: 0.7445\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5219 - loss: 0.6868 - val_accuracy: 0.3158 - val_loss: 0.7490\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5668 - loss: 0.6829 - val_accuracy: 0.3158 - val_loss: 0.7459\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5981 - loss: 0.6688 - val_accuracy: 0.3158 - val_loss: 0.7527\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5876 - loss: 0.6711 - val_accuracy: 0.3158 - val_loss: 0.7447\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5783 - loss: 0.6785 - val_accuracy: 0.3158 - val_loss: 0.7447\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5772 - loss: 0.6706 - val_accuracy: 0.1579 - val_loss: 0.7493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Loop done for INFY.NS\n",
      "Entered the Loop for ITC.NS\n",
      "Validation Data Collected for ITC.NS\n",
      "Training Data Collected for ITC.NS\n",
      "Searching for best hyper-params for ITC.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ITC.NS/tuner0.json\n",
      "Hyper-Params for best model of ITC.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5334 - loss: 0.7014 - val_accuracy: 0.5263 - val_loss: 0.6864\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6325 - loss: 0.6713 - val_accuracy: 0.5263 - val_loss: 0.6821\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5887 - loss: 0.6925 - val_accuracy: 0.7895 - val_loss: 0.6770\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6096 - loss: 0.6678 - val_accuracy: 0.7895 - val_loss: 0.6731\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5898 - loss: 0.6712 - val_accuracy: 0.8421 - val_loss: 0.6713\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6013 - loss: 0.6718 - val_accuracy: 0.8421 - val_loss: 0.6676\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6430 - loss: 0.6569 - val_accuracy: 0.8421 - val_loss: 0.6659\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5898 - loss: 0.6685 - val_accuracy: 0.8421 - val_loss: 0.6639\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6117 - loss: 0.6563 - val_accuracy: 0.8421 - val_loss: 0.6618\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5334 - loss: 0.6584 - val_accuracy: 0.8421 - val_loss: 0.6606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for ITC.NS\n",
      "Entered the Loop for JIOFIN.NS\n",
      "Validation Data Collected for JIOFIN.NS\n",
      "Training Data Collected for JIOFIN.NS\n",
      "Searching for best hyper-params for JIOFIN.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_JIOFIN.NS/tuner0.json\n",
      "Hyper-Params for best model of JIOFIN.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6024 - loss: 0.6820 - val_accuracy: 0.3684 - val_loss: 0.7525\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6774 - loss: 0.6379 - val_accuracy: 0.3684 - val_loss: 0.8043\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7015 - loss: 0.6312 - val_accuracy: 0.3684 - val_loss: 0.8241\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7098 - loss: 0.6149 - val_accuracy: 0.3684 - val_loss: 0.8357\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7213 - loss: 0.5977 - val_accuracy: 0.3684 - val_loss: 0.8638\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6889 - loss: 0.6137 - val_accuracy: 0.3684 - val_loss: 0.8844\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7432 - loss: 0.5781 - val_accuracy: 0.3684 - val_loss: 0.9616\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6670 - loss: 0.5819 - val_accuracy: 0.3684 - val_loss: 0.9080\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7004 - loss: 0.5874 - val_accuracy: 0.3684 - val_loss: 0.9478\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7004 - loss: 0.5831 - val_accuracy: 0.3684 - val_loss: 0.9912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for JIOFIN.NS\n",
      "Entered the Loop for JSWSTEEL.NS\n",
      "Validation Data Collected for JSWSTEEL.NS\n",
      "Training Data Collected for JSWSTEEL.NS\n",
      "Searching for best hyper-params for JSWSTEEL.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_JSWSTEEL.NS/tuner0.json\n",
      "Hyper-Params for best model of JSWSTEEL.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5323 - loss: 0.7058 - val_accuracy: 0.4737 - val_loss: 0.6900\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4907 - loss: 0.6931 - val_accuracy: 0.4211 - val_loss: 0.6896\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6534 - loss: 0.6795 - val_accuracy: 0.4211 - val_loss: 0.6880\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7443 - loss: 0.6592 - val_accuracy: 0.4737 - val_loss: 0.6881\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5991 - loss: 0.6746 - val_accuracy: 0.5263 - val_loss: 0.6925\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6566 - loss: 0.6619 - val_accuracy: 0.5263 - val_loss: 0.6951\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5323 - loss: 0.6765 - val_accuracy: 0.5263 - val_loss: 0.6944\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6774 - loss: 0.6500 - val_accuracy: 0.5263 - val_loss: 0.6964\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6440 - loss: 0.6748 - val_accuracy: 0.5263 - val_loss: 0.7076\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6972 - loss: 0.6414 - val_accuracy: 0.5263 - val_loss: 0.7109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for JSWSTEEL.NS\n",
      "Entered the Loop for KOTAKBANK.NS\n",
      "Validation Data Collected for KOTAKBANK.NS\n",
      "Training Data Collected for KOTAKBANK.NS\n",
      "Searching for best hyper-params for KOTAKBANK.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_KOTAKBANK.NS/tuner0.json\n",
      "Hyper-Params for best model of KOTAKBANK.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5959 - loss: 0.8265 - val_accuracy: 0.5263 - val_loss: 0.6887\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5312 - loss: 0.7702 - val_accuracy: 0.5263 - val_loss: 0.6868\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5772 - loss: 0.7387 - val_accuracy: 0.6842 - val_loss: 0.6839\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5575 - loss: 0.7208 - val_accuracy: 0.7895 - val_loss: 0.6798\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6189 - loss: 0.6778 - val_accuracy: 0.7895 - val_loss: 0.6786\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5783 - loss: 0.6703 - val_accuracy: 0.7895 - val_loss: 0.6763\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6106 - loss: 0.6596 - val_accuracy: 0.7368 - val_loss: 0.6751\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6221 - loss: 0.6497 - val_accuracy: 0.6842 - val_loss: 0.6739\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6681 - loss: 0.6436 - val_accuracy: 0.5789 - val_loss: 0.6589\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7119 - loss: 0.6217 - val_accuracy: 0.5789 - val_loss: 0.6373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for KOTAKBANK.NS\n",
      "Entered the Loop for LT.NS\n",
      "Validation Data Collected for LT.NS\n",
      "Training Data Collected for LT.NS\n",
      "Searching for best hyper-params for LT.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_LT.NS/tuner0.json\n",
      "Hyper-Params for best model of LT.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4802 - loss: 0.6976 - val_accuracy: 0.2632 - val_loss: 0.7074\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6096 - loss: 0.6726 - val_accuracy: 0.2632 - val_loss: 0.7126\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5679 - loss: 0.6669 - val_accuracy: 0.4211 - val_loss: 0.7153\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6221 - loss: 0.6497 - val_accuracy: 0.4211 - val_loss: 0.7151\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6440 - loss: 0.6367 - val_accuracy: 0.3684 - val_loss: 0.7158\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6243 - loss: 0.6449 - val_accuracy: 0.3684 - val_loss: 0.7164\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6462 - loss: 0.6360 - val_accuracy: 0.3684 - val_loss: 0.7165\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7119 - loss: 0.6281 - val_accuracy: 0.3684 - val_loss: 0.7177\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7213 - loss: 0.6031 - val_accuracy: 0.3684 - val_loss: 0.7182\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6785 - loss: 0.6187 - val_accuracy: 0.3684 - val_loss: 0.7166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for LT.NS\n",
      "Entered the Loop for M&M.NS\n",
      "Validation Data Collected for M&M.NS\n",
      "Training Data Collected for M&M.NS\n",
      "Searching for best hyper-params for M&M.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_M&M.NS/tuner0.json\n",
      "Hyper-Params for best model of M&M.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6096 - loss: 0.6873 - val_accuracy: 0.7895 - val_loss: 0.6729\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5460 - loss: 0.6904 - val_accuracy: 0.7895 - val_loss: 0.6656\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5761 - loss: 0.6753 - val_accuracy: 0.7368 - val_loss: 0.6575\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5668 - loss: 0.6799 - val_accuracy: 0.7368 - val_loss: 0.6508\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5542 - loss: 0.6837 - val_accuracy: 0.7368 - val_loss: 0.6445\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5334 - loss: 0.6912 - val_accuracy: 0.7368 - val_loss: 0.6389\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5761 - loss: 0.6832 - val_accuracy: 0.7368 - val_loss: 0.6334\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5219 - loss: 0.6916 - val_accuracy: 0.7368 - val_loss: 0.6288\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6440 - loss: 0.6680 - val_accuracy: 0.7368 - val_loss: 0.6252\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6451 - loss: 0.6639 - val_accuracy: 0.7368 - val_loss: 0.6219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for M&M.NS\n",
      "Entered the Loop for MARUTI.NS\n",
      "Validation Data Collected for MARUTI.NS\n",
      "Training Data Collected for MARUTI.NS\n",
      "Searching for best hyper-params for MARUTI.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_MARUTI.NS/tuner0.json\n",
      "Hyper-Params for best model of MARUTI.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4896 - loss: 0.7139 - val_accuracy: 0.1579 - val_loss: 0.7787\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5334 - loss: 0.6706 - val_accuracy: 0.1579 - val_loss: 0.8652\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5783 - loss: 0.6664 - val_accuracy: 0.1579 - val_loss: 0.9362\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5920 - loss: 0.6538 - val_accuracy: 0.1579 - val_loss: 0.9944\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6347 - loss: 0.6548 - val_accuracy: 0.1579 - val_loss: 1.0621\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7536 - loss: 0.6256 - val_accuracy: 0.1579 - val_loss: 1.1473\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6879 - loss: 0.6183 - val_accuracy: 0.1579 - val_loss: 1.1977\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6358 - loss: 0.6299 - val_accuracy: 0.1579 - val_loss: 1.2155\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7536 - loss: 0.6147 - val_accuracy: 0.1579 - val_loss: 1.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7328 - loss: 0.6045 - val_accuracy: 0.1579 - val_loss: 1.2799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Loop done for MARUTI.NS\n",
      "Entered the Loop for MAXHEALTH.NS\n",
      "Validation Data Collected for MAXHEALTH.NS\n",
      "Training Data Collected for MAXHEALTH.NS\n",
      "Searching for best hyper-params for MAXHEALTH.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_MAXHEALTH.NS/tuner0.json\n",
      "Hyper-Params for best model of MAXHEALTH.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6221 - loss: 0.6778 - val_accuracy: 0.6842 - val_loss: 0.6651\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6002 - loss: 0.6789 - val_accuracy: 0.6842 - val_loss: 0.6683\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6347 - loss: 0.6644 - val_accuracy: 0.7368 - val_loss: 0.6700\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6659 - loss: 0.6491 - val_accuracy: 0.6842 - val_loss: 0.6737\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6566 - loss: 0.6492 - val_accuracy: 0.5789 - val_loss: 0.6780\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6889 - loss: 0.6399 - val_accuracy: 0.6316 - val_loss: 0.6833\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6577 - loss: 0.6347 - val_accuracy: 0.5789 - val_loss: 0.6891\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7328 - loss: 0.6107 - val_accuracy: 0.5789 - val_loss: 0.6972\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6994 - loss: 0.6083 - val_accuracy: 0.5263 - val_loss: 0.7085\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6462 - loss: 0.6094 - val_accuracy: 0.5789 - val_loss: 0.7241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for MAXHEALTH.NS\n",
      "Entered the Loop for NESTLEIND.NS\n",
      "Validation Data Collected for NESTLEIND.NS\n",
      "Training Data Collected for NESTLEIND.NS\n",
      "Searching for best hyper-params for NESTLEIND.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_NESTLEIND.NS/tuner0.json\n",
      "Hyper-Params for best model of NESTLEIND.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6013 - loss: 0.6805 - val_accuracy: 0.7895 - val_loss: 0.6014\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5909 - loss: 0.6740 - val_accuracy: 0.7895 - val_loss: 0.6000\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6210 - loss: 0.6698 - val_accuracy: 0.7895 - val_loss: 0.5981\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6096 - loss: 0.6559 - val_accuracy: 0.7895 - val_loss: 0.5966\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6325 - loss: 0.6584 - val_accuracy: 0.7895 - val_loss: 0.5962\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6013 - loss: 0.6638 - val_accuracy: 0.7895 - val_loss: 0.5973\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6013 - loss: 0.6651 - val_accuracy: 0.7895 - val_loss: 0.5981\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6534 - loss: 0.6412 - val_accuracy: 0.7895 - val_loss: 0.5987\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6325 - loss: 0.6453 - val_accuracy: 0.7895 - val_loss: 0.5994\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5909 - loss: 0.6550 - val_accuracy: 0.7895 - val_loss: 0.6007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for NESTLEIND.NS\n",
      "Entered the Loop for NTPC.NS\n",
      "Validation Data Collected for NTPC.NS\n",
      "Training Data Collected for NTPC.NS\n",
      "Searching for best hyper-params for NTPC.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_NTPC.NS/tuner0.json\n",
      "Hyper-Params for best model of NTPC.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5126 - loss: 0.6866 - val_accuracy: 0.4211 - val_loss: 0.7014\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6347 - loss: 0.6714 - val_accuracy: 0.4211 - val_loss: 0.7096\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6096 - loss: 0.6629 - val_accuracy: 0.3684 - val_loss: 0.7186\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5690 - loss: 0.6666 - val_accuracy: 0.2632 - val_loss: 0.7252\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6117 - loss: 0.6655 - val_accuracy: 0.3158 - val_loss: 0.7307\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6002 - loss: 0.6460 - val_accuracy: 0.4211 - val_loss: 0.7348\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6325 - loss: 0.6393 - val_accuracy: 0.4211 - val_loss: 0.7340\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6232 - loss: 0.6442 - val_accuracy: 0.4211 - val_loss: 0.7325\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6117 - loss: 0.6492 - val_accuracy: 0.4211 - val_loss: 0.7344\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5898 - loss: 0.6317 - val_accuracy: 0.4211 - val_loss: 0.7369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Loop done for NTPC.NS\n",
      "Entered the Loop for ONGC.NS\n",
      "Validation Data Collected for ONGC.NS\n",
      "Training Data Collected for ONGC.NS\n",
      "Searching for best hyper-params for ONGC.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ONGC.NS/tuner0.json\n",
      "Hyper-Params for best model of ONGC.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4436 - loss: 0.7073 - val_accuracy: 0.5263 - val_loss: 0.7236\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5449 - loss: 0.6885 - val_accuracy: 0.3684 - val_loss: 0.7244\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5761 - loss: 0.6659 - val_accuracy: 0.3684 - val_loss: 0.7246\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5898 - loss: 0.6618 - val_accuracy: 0.4211 - val_loss: 0.7260\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5208 - loss: 0.6655 - val_accuracy: 0.4211 - val_loss: 0.7256\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5104 - loss: 0.6640 - val_accuracy: 0.3684 - val_loss: 0.7285\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6221 - loss: 0.6339 - val_accuracy: 0.3684 - val_loss: 0.7303\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5761 - loss: 0.6405 - val_accuracy: 0.4211 - val_loss: 0.7304\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6243 - loss: 0.6417 - val_accuracy: 0.5263 - val_loss: 0.7322\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5679 - loss: 0.6382 - val_accuracy: 0.5263 - val_loss: 0.7339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for ONGC.NS\n",
      "Entered the Loop for POWERGRID.NS\n",
      "Validation Data Collected for POWERGRID.NS\n",
      "Training Data Collected for POWERGRID.NS\n",
      "Searching for best hyper-params for POWERGRID.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_POWERGRID.NS/tuner0.json\n",
      "Hyper-Params for best model of POWERGRID.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5761 - loss: 0.6979 - val_accuracy: 0.5263 - val_loss: 0.6823\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6117 - loss: 0.6721 - val_accuracy: 0.5789 - val_loss: 0.6777\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5772 - loss: 0.6811 - val_accuracy: 0.6842 - val_loss: 0.6738\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5647 - loss: 0.6899 - val_accuracy: 0.6842 - val_loss: 0.6733\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6545 - loss: 0.6756 - val_accuracy: 0.6842 - val_loss: 0.6715\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5230 - loss: 0.6807 - val_accuracy: 0.6842 - val_loss: 0.6717\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6002 - loss: 0.6659 - val_accuracy: 0.6842 - val_loss: 0.6707\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4896 - loss: 0.6922 - val_accuracy: 0.7368 - val_loss: 0.6696\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5679 - loss: 0.6735 - val_accuracy: 0.6842 - val_loss: 0.6676\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6462 - loss: 0.6587 - val_accuracy: 0.7368 - val_loss: 0.6664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for POWERGRID.NS\n",
      "Entered the Loop for RELIANCE.NS\n",
      "Validation Data Collected for RELIANCE.NS\n",
      "Training Data Collected for RELIANCE.NS\n",
      "Searching for best hyper-params for RELIANCE.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_RELIANCE.NS/tuner0.json\n",
      "Hyper-Params for best model of RELIANCE.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4562 - loss: 0.6994 - val_accuracy: 0.4737 - val_loss: 0.7077\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6336 - loss: 0.6539 - val_accuracy: 0.4737 - val_loss: 0.7086\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6451 - loss: 0.6566 - val_accuracy: 0.4737 - val_loss: 0.7064\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6555 - loss: 0.6577 - val_accuracy: 0.4737 - val_loss: 0.7060\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6013 - loss: 0.6530 - val_accuracy: 0.4737 - val_loss: 0.7060\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6336 - loss: 0.6428 - val_accuracy: 0.4737 - val_loss: 0.7078\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6440 - loss: 0.6527 - val_accuracy: 0.4737 - val_loss: 0.7073\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6462 - loss: 0.6599 - val_accuracy: 0.4737 - val_loss: 0.7089\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6117 - loss: 0.6476 - val_accuracy: 0.4737 - val_loss: 0.7067\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6659 - loss: 0.6299 - val_accuracy: 0.4737 - val_loss: 0.7083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for RELIANCE.NS\n",
      "Entered the Loop for SBILIFE.NS\n",
      "Validation Data Collected for SBILIFE.NS\n",
      "Training Data Collected for SBILIFE.NS\n",
      "Searching for best hyper-params for SBILIFE.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_SBILIFE.NS/tuner0.json\n",
      "Hyper-Params for best model of SBILIFE.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4113 - loss: 0.7090 - val_accuracy: 0.6316 - val_loss: 0.6964\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5323 - loss: 0.6914 - val_accuracy: 0.6842 - val_loss: 0.6889\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5761 - loss: 0.6826 - val_accuracy: 0.7895 - val_loss: 0.6829\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5219 - loss: 0.6854 - val_accuracy: 0.8421 - val_loss: 0.6798\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6451 - loss: 0.6775 - val_accuracy: 0.8421 - val_loss: 0.6760\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5898 - loss: 0.6729 - val_accuracy: 0.8421 - val_loss: 0.6739\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6232 - loss: 0.6686 - val_accuracy: 0.8421 - val_loss: 0.6701\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6440 - loss: 0.6715 - val_accuracy: 0.7895 - val_loss: 0.6678\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6419 - loss: 0.6701 - val_accuracy: 0.6842 - val_loss: 0.6663\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6649 - loss: 0.6576 - val_accuracy: 0.7895 - val_loss: 0.6639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Loop done for SBILIFE.NS\n",
      "Entered the Loop for SHRIRAMFIN.NS\n",
      "Validation Data Collected for SHRIRAMFIN.NS\n",
      "Training Data Collected for SHRIRAMFIN.NS\n",
      "Searching for best hyper-params for SHRIRAMFIN.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_SHRIRAMFIN.NS/tuner0.json\n",
      "Hyper-Params for best model of SHRIRAMFIN.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5887 - loss: 0.6746 - val_accuracy: 0.4211 - val_loss: 0.7552\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6002 - loss: 0.6486 - val_accuracy: 0.4211 - val_loss: 0.7542\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5920 - loss: 0.6713 - val_accuracy: 0.4211 - val_loss: 0.7532\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6117 - loss: 0.6352 - val_accuracy: 0.4211 - val_loss: 0.7523\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5783 - loss: 0.6365 - val_accuracy: 0.4211 - val_loss: 0.7516\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6534 - loss: 0.6247 - val_accuracy: 0.4211 - val_loss: 0.7548\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6440 - loss: 0.6292 - val_accuracy: 0.4211 - val_loss: 0.7524\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6232 - loss: 0.6334 - val_accuracy: 0.4211 - val_loss: 0.7529\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6868 - loss: 0.6115 - val_accuracy: 0.4211 - val_loss: 0.7529\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6555 - loss: 0.6332 - val_accuracy: 0.4211 - val_loss: 0.7540\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for SHRIRAMFIN.NS\n",
      "Entered the Loop for SBIN.NS\n",
      "Validation Data Collected for SBIN.NS\n",
      "Training Data Collected for SBIN.NS\n",
      "Searching for best hyper-params for SBIN.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_SBIN.NS/tuner0.json\n",
      "Hyper-Params for best model of SBIN.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4562 - loss: 0.6921 - val_accuracy: 0.5263 - val_loss: 0.6931\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6462 - loss: 0.6635 - val_accuracy: 0.3684 - val_loss: 0.7005\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6774 - loss: 0.6517 - val_accuracy: 0.4211 - val_loss: 0.7050\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6451 - loss: 0.6470 - val_accuracy: 0.3684 - val_loss: 0.7128\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7328 - loss: 0.6175 - val_accuracy: 0.3684 - val_loss: 0.7204\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6566 - loss: 0.6290 - val_accuracy: 0.3684 - val_loss: 0.7250\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6774 - loss: 0.6255 - val_accuracy: 0.3684 - val_loss: 0.7315\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6347 - loss: 0.6387 - val_accuracy: 0.3684 - val_loss: 0.7398\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6774 - loss: 0.6079 - val_accuracy: 0.5263 - val_loss: 0.7493\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7223 - loss: 0.6027 - val_accuracy: 0.5263 - val_loss: 0.7633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for SBIN.NS\n",
      "Entered the Loop for TCS.NS\n",
      "Validation Data Collected for TCS.NS\n",
      "Training Data Collected for TCS.NS\n",
      "Searching for best hyper-params for TCS.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TCS.NS/tuner0.json\n",
      "Hyper-Params for best model of TCS.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5772 - loss: 0.7021 - val_accuracy: 0.5789 - val_loss: 0.6752\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5909 - loss: 0.6837 - val_accuracy: 0.6316 - val_loss: 0.6775\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6566 - loss: 0.6693 - val_accuracy: 0.6842 - val_loss: 0.6814\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6577 - loss: 0.6620 - val_accuracy: 0.6842 - val_loss: 0.6861\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7306 - loss: 0.6414 - val_accuracy: 0.6842 - val_loss: 0.6873\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6785 - loss: 0.6400 - val_accuracy: 0.6842 - val_loss: 0.6846\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7547 - loss: 0.6228 - val_accuracy: 0.6842 - val_loss: 0.6828\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7443 - loss: 0.6228 - val_accuracy: 0.6842 - val_loss: 0.6816\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6911 - loss: 0.6183 - val_accuracy: 0.6842 - val_loss: 0.6794\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7223 - loss: 0.6091 - val_accuracy: 0.6842 - val_loss: 0.6806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for TCS.NS\n",
      "Entered the Loop for TATACONSUM.NS\n",
      "Validation Data Collected for TATACONSUM.NS\n",
      "Training Data Collected for TATACONSUM.NS\n",
      "Searching for best hyper-params for TATACONSUM.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TATACONSUM.NS/tuner0.json\n",
      "Hyper-Params for best model of TATACONSUM.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6221 - loss: 0.6806 - val_accuracy: 0.7368 - val_loss: 0.6740\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6117 - loss: 0.6712 - val_accuracy: 0.7368 - val_loss: 0.6729\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5909 - loss: 0.6717 - val_accuracy: 0.7368 - val_loss: 0.6721\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6117 - loss: 0.6629 - val_accuracy: 0.7368 - val_loss: 0.6716\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5805 - loss: 0.6724 - val_accuracy: 0.7368 - val_loss: 0.6714\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6325 - loss: 0.6503 - val_accuracy: 0.7368 - val_loss: 0.6710\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6430 - loss: 0.6387 - val_accuracy: 0.7368 - val_loss: 0.6707\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6221 - loss: 0.6456 - val_accuracy: 0.7368 - val_loss: 0.6705\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6325 - loss: 0.6348 - val_accuracy: 0.7368 - val_loss: 0.6707\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5805 - loss: 0.6600 - val_accuracy: 0.7368 - val_loss: 0.6708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for TATACONSUM.NS\n",
      "Entered the Loop for TATAMOTORS.NS\n",
      "Validation Data Collected for TATAMOTORS.NS\n",
      "Training Data Collected for TATAMOTORS.NS\n",
      "Searching for best hyper-params for TATAMOTORS.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TATAMOTORS.NS/tuner0.json\n",
      "Hyper-Params for best model of TATAMOTORS.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5011 - loss: 0.6878 - val_accuracy: 0.5789 - val_loss: 0.6918\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6232 - loss: 0.6748 - val_accuracy: 0.5789 - val_loss: 0.6801\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5783 - loss: 0.6661 - val_accuracy: 0.7895 - val_loss: 0.6710\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6002 - loss: 0.6604 - val_accuracy: 0.7895 - val_loss: 0.6649\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6545 - loss: 0.6509 - val_accuracy: 0.6316 - val_loss: 0.6601\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6210 - loss: 0.6433 - val_accuracy: 0.6316 - val_loss: 0.6548\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6419 - loss: 0.6264 - val_accuracy: 0.6316 - val_loss: 0.6501\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6106 - loss: 0.6138 - val_accuracy: 0.6316 - val_loss: 0.6465\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6232 - loss: 0.6271 - val_accuracy: 0.7368 - val_loss: 0.6440\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6670 - loss: 0.6012 - val_accuracy: 0.7368 - val_loss: 0.6427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Loop done for TATAMOTORS.NS\n",
      "Entered the Loop for TATASTEEL.NS\n",
      "Validation Data Collected for TATASTEEL.NS\n",
      "Training Data Collected for TATASTEEL.NS\n",
      "Searching for best hyper-params for TATASTEEL.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TATASTEEL.NS/tuner0.json\n",
      "Hyper-Params for best model of TATASTEEL.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6336 - loss: 0.6646 - val_accuracy: 0.6316 - val_loss: 0.6412\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7662 - loss: 0.6161 - val_accuracy: 0.6316 - val_loss: 0.6337\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7317 - loss: 0.5898 - val_accuracy: 0.6316 - val_loss: 0.6279\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6210 - loss: 0.6328 - val_accuracy: 0.6316 - val_loss: 0.6355\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7338 - loss: 0.5650 - val_accuracy: 0.6316 - val_loss: 0.6338\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7547 - loss: 0.5479 - val_accuracy: 0.6316 - val_loss: 0.6429\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7547 - loss: 0.5446 - val_accuracy: 0.6316 - val_loss: 0.6415\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7338 - loss: 0.5447 - val_accuracy: 0.6316 - val_loss: 0.6473\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7766 - loss: 0.5053 - val_accuracy: 0.6316 - val_loss: 0.6773\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7662 - loss: 0.5059 - val_accuracy: 0.6316 - val_loss: 0.6556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for TATASTEEL.NS\n",
      "Entered the Loop for TECHM.NS\n",
      "Validation Data Collected for TECHM.NS\n",
      "Training Data Collected for TECHM.NS\n",
      "Searching for best hyper-params for TECHM.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TECHM.NS/tuner0.json\n",
      "Hyper-Params for best model of TECHM.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5668 - loss: 0.6910 - val_accuracy: 0.6842 - val_loss: 0.6858\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5991 - loss: 0.6836 - val_accuracy: 0.7368 - val_loss: 0.6855\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5564 - loss: 0.6777 - val_accuracy: 0.7368 - val_loss: 0.6859\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5761 - loss: 0.6724 - val_accuracy: 0.7368 - val_loss: 0.6862\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5991 - loss: 0.6661 - val_accuracy: 0.7895 - val_loss: 0.6870\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6002 - loss: 0.6683 - val_accuracy: 0.5263 - val_loss: 0.6881\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6430 - loss: 0.6497 - val_accuracy: 0.4737 - val_loss: 0.6891\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6117 - loss: 0.6615 - val_accuracy: 0.4737 - val_loss: 0.6901\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6221 - loss: 0.6551 - val_accuracy: 0.4737 - val_loss: 0.6912\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6013 - loss: 0.6589 - val_accuracy: 0.4737 - val_loss: 0.6922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for TECHM.NS\n",
      "Entered the Loop for TITAN.NS\n",
      "Validation Data Collected for TITAN.NS\n",
      "Training Data Collected for TITAN.NS\n",
      "Searching for best hyper-params for TITAN.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TITAN.NS/tuner0.json\n",
      "Hyper-Params for best model of TITAN.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5553 - loss: 0.6912 - val_accuracy: 0.8947 - val_loss: 0.6475\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5291 - loss: 0.6917 - val_accuracy: 0.8947 - val_loss: 0.6495\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5427 - loss: 0.6883 - val_accuracy: 0.8421 - val_loss: 0.6541\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5115 - loss: 0.6836 - val_accuracy: 0.7368 - val_loss: 0.6604\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6545 - loss: 0.6729 - val_accuracy: 0.7368 - val_loss: 0.6626\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6024 - loss: 0.6851 - val_accuracy: 0.7368 - val_loss: 0.6575\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6221 - loss: 0.6827 - val_accuracy: 0.6842 - val_loss: 0.6574\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6210 - loss: 0.6747 - val_accuracy: 0.6842 - val_loss: 0.6579\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6221 - loss: 0.6737 - val_accuracy: 0.6316 - val_loss: 0.6657\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6106 - loss: 0.6741 - val_accuracy: 0.6316 - val_loss: 0.6648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Loop done for TITAN.NS\n",
      "Entered the Loop for TRENT.NS\n",
      "Validation Data Collected for TRENT.NS\n",
      "Training Data Collected for TRENT.NS\n",
      "Searching for best hyper-params for TRENT.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_TRENT.NS/tuner0.json\n",
      "Hyper-Params for best model of TRENT.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6325 - loss: 0.6736 - val_accuracy: 0.5263 - val_loss: 0.6965\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6117 - loss: 0.6757 - val_accuracy: 0.5263 - val_loss: 0.6950\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6221 - loss: 0.6472 - val_accuracy: 0.5263 - val_loss: 0.6956\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6117 - loss: 0.6548 - val_accuracy: 0.4737 - val_loss: 0.6989\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5805 - loss: 0.6729 - val_accuracy: 0.5263 - val_loss: 0.6948\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6221 - loss: 0.6536 - val_accuracy: 0.5263 - val_loss: 0.6937\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6430 - loss: 0.6567 - val_accuracy: 0.5263 - val_loss: 0.6943\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6325 - loss: 0.6341 - val_accuracy: 0.5263 - val_loss: 0.6979\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6117 - loss: 0.6577 - val_accuracy: 0.4737 - val_loss: 0.6999\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6534 - loss: 0.6318 - val_accuracy: 0.5263 - val_loss: 0.7025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for TRENT.NS\n",
      "Entered the Loop for ULTRACEMCO.NS\n",
      "Validation Data Collected for ULTRACEMCO.NS\n",
      "Training Data Collected for ULTRACEMCO.NS\n",
      "Searching for best hyper-params for ULTRACEMCO.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_ULTRACEMCO.NS/tuner0.json\n",
      "Hyper-Params for best model of ULTRACEMCO.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4353 - loss: 0.7023 - val_accuracy: 0.2105 - val_loss: 0.7466\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5542 - loss: 0.6903 - val_accuracy: 0.2105 - val_loss: 0.7342\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5783 - loss: 0.6811 - val_accuracy: 0.2105 - val_loss: 0.7377\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5772 - loss: 0.6878 - val_accuracy: 0.3684 - val_loss: 0.7309\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6670 - loss: 0.6597 - val_accuracy: 0.3158 - val_loss: 0.7259\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6440 - loss: 0.6484 - val_accuracy: 0.2632 - val_loss: 0.7252\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6128 - loss: 0.6767 - val_accuracy: 0.2632 - val_loss: 0.7207\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6117 - loss: 0.6748 - val_accuracy: 0.2105 - val_loss: 0.7156\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6336 - loss: 0.6486 - val_accuracy: 0.2105 - val_loss: 0.7157\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6764 - loss: 0.6617 - val_accuracy: 0.2632 - val_loss: 0.7102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Loop done for ULTRACEMCO.NS\n",
      "Entered the Loop for WIPRO.NS\n",
      "Validation Data Collected for WIPRO.NS\n",
      "Training Data Collected for WIPRO.NS\n",
      "Searching for best hyper-params for WIPRO.NS model\n",
      "Reloading Tuner from lstm_tuning/nifty_predict_WIPRO.NS/tuner0.json\n",
      "Hyper-Params for best model of WIPRO.NS have been found\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 9 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5345 - loss: 0.6960 - val_accuracy: 0.2105 - val_loss: 0.7524\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6555 - loss: 0.6610 - val_accuracy: 0.2105 - val_loss: 0.7721\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6336 - loss: 0.6492 - val_accuracy: 0.2105 - val_loss: 0.7626\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6128 - loss: 0.6527 - val_accuracy: 0.2105 - val_loss: 0.7638\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6440 - loss: 0.6303 - val_accuracy: 0.2632 - val_loss: 0.7351\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6232 - loss: 0.6373 - val_accuracy: 0.4211 - val_loss: 0.7357\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6336 - loss: 0.6286 - val_accuracy: 0.5263 - val_loss: 0.7279\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6128 - loss: 0.6171 - val_accuracy: 0.5263 - val_loss: 0.7133\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6336 - loss: 0.6132 - val_accuracy: 0.5789 - val_loss: 0.7066\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6232 - loss: 0.6181 - val_accuracy: 0.6842 - val_loss: 0.6998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Loop done for WIPRO.NS\n",
      "Execution Done ----- XXXX -----\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().date()\n",
    "base_date = today - timedelta(days=180)\n",
    "validation_base_date = today - timedelta(days=70)\n",
    "accuracy_dict = {}\n",
    "tickers = nifty50_tickers[:13] + nifty50_tickers[15:40] + nifty50_tickers[41:]\n",
    "\n",
    "for symbol in tickers:\n",
    "    print('Entered the Loop for',symbol)\n",
    "    \n",
    "    # Initialize training window\n",
    "    start_date = base_date\n",
    "    end_date = start_date + timedelta(days=51)\n",
    "\n",
    "    # Initialize validation window\n",
    "    validation_start_date = validation_base_date\n",
    "    validation_end_date = validation_start_date + timedelta(days=51)\n",
    "\n",
    "    # Create validation dataset\n",
    "    validation_input = []\n",
    "    validation_labels = []\n",
    "    while validation_end_date < today:\n",
    "        validation_iteration_data = get_ticker_data(symbol, validation_start_date, validation_end_date)\n",
    "\n",
    "        if len(validation_iteration_data) < 31:\n",
    "            validation_start_date += timedelta(days=1)\n",
    "            validation_end_date += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        label = int(validation_iteration_data['Return'].iloc[-1] > 0)\n",
    "        validation_iteration_data = validation_iteration_data.iloc[:-1].tail(30)\n",
    "\n",
    "        if len(validation_iteration_data) < 30:\n",
    "            validation_start_date += timedelta(days=1)\n",
    "            validation_end_date += timedelta(days=1)\n",
    "            continue\n",
    "        \n",
    "        validation_input.append(validation_iteration_data)\n",
    "        validation_labels.append(label)\n",
    "\n",
    "        validation_start_date += timedelta(days=1)\n",
    "        validation_end_date += timedelta(days=1)\n",
    "\n",
    "    validation_input, validation_labels = dataframe_to_np(validation_input, validation_labels)\n",
    "\n",
    "    print('Validation Data Collected for', symbol)\n",
    "    \n",
    "    # Create training dataset\n",
    "    input_data = []\n",
    "    output_labels = []\n",
    "    while end_date < validation_base_date:\n",
    "        data = get_ticker_data(symbol, start_date, end_date)\n",
    "\n",
    "        if len(data) < 30:\n",
    "            start_date += timedelta(days=1)\n",
    "            end_date += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        label = int(data['Return'].iloc[-1] > 0)\n",
    "        data = data.iloc[:-1].tail(30)\n",
    "\n",
    "        if len(data) < 30:\n",
    "            start_date += timedelta(days=1)\n",
    "            end_date += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        input_data.append(data)\n",
    "        output_labels.append(label)\n",
    "\n",
    "        start_date += timedelta(days=1)\n",
    "        end_date += timedelta(days=1)\n",
    "\n",
    "    input_data, output_labels = dataframe_to_np(input_data, output_labels)\n",
    "    # Build and train model\n",
    "    \n",
    "    print('Training Data Collected for',symbol)\n",
    "    \n",
    "    accuracy = train_model(symbol ,input_data , output_labels , validation_input , validation_labels)\n",
    "    accuracy_dict[symbol] = accuracy\n",
    "    \n",
    "    print('Loop done for',symbol)\n",
    "\n",
    "print('Execution Done ----- XXXX -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b5a5c-79db-4102-bf85-43b35f4a49bc",
   "metadata": {},
   "source": [
    "#### Below is the piece of code to sort the obtained accuracies from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb2e7f5a-8798-4c04-97f7-16d3e2327803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN.NS: 89.47%\n",
      "HCLTECH.NS: 84.21%\n",
      "ITC.NS: 84.21%\n",
      "NESTLEIND.NS: 78.95%\n",
      "SBILIFE.NS: 78.95%\n",
      "BEL.NS: 73.68%\n",
      "COALINDIA.NS: 73.68%\n",
      "HDFCLIFE.NS: 73.68%\n",
      "M&M.NS: 73.68%\n",
      "POWERGRID.NS: 73.68%\n",
      "TATACONSUM.NS: 73.68%\n",
      "TATAMOTORS.NS: 73.68%\n",
      "TECHM.NS: 73.68%\n",
      "MAXHEALTH.NS: 68.42%\n",
      "WIPRO.NS: 68.42%\n",
      "ADANIENT.NS: 63.16%\n",
      "AXISBANK.NS: 63.16%\n",
      "CIPLA.NS: 63.16%\n",
      "INDIGO.NS: 63.16%\n",
      "TATASTEEL.NS: 63.16%\n",
      "ADANIPORTS.NS: 57.89%\n",
      "APOLLOHOSP.NS: 57.89%\n",
      "BAJAJ-AUTO.NS: 57.89%\n",
      "BAJAJFINSV.NS: 57.89%\n",
      "KOTAKBANK.NS: 57.89%\n",
      "TCS.NS: 57.89%\n",
      "GRASIM.NS: 52.63%\n",
      "HINDALCO.NS: 52.63%\n",
      "ONGC.NS: 52.63%\n",
      "SBIN.NS: 52.63%\n",
      "TRENT.NS: 52.63%\n",
      "ASIANPAINT.NS: 47.37%\n",
      "BAJFINANCE.NS: 47.37%\n",
      "RELIANCE.NS: 47.37%\n",
      "JSWSTEEL.NS: 42.11%\n",
      "NTPC.NS: 42.11%\n",
      "SHRIRAMFIN.NS: 42.11%\n",
      "DRREDDY.NS: 36.84%\n",
      "JIOFIN.NS: 36.84%\n",
      "BHARTIARTL.NS: 31.58%\n",
      "ICICIBANK.NS: 31.58%\n",
      "INFY.NS: 31.58%\n",
      "HINDUNILVR.NS: 26.32%\n",
      "LT.NS: 26.32%\n",
      "ULTRACEMCO.NS: 26.32%\n",
      "HDFCBANK.NS: 15.79%\n",
      "MARUTI.NS: 15.79%\n"
     ]
    }
   ],
   "source": [
    "sorted_accuracies = sorted(accuracy_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for symbol, accuracy in sorted_accuracies:\n",
    "    print(f\"{symbol}: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d9c32-3e3c-4a01-9d8c-76f6338f5ef2",
   "metadata": {},
   "source": [
    "#### Now we only choose those companies for which we have a prediction accuracy > threshold, for this project, i have decided to keep a threshold of 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ccf9d8-17ab-4bff-ab37-7421dd89b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADANIENT.NS': 0.631578947368421, 'AXISBANK.NS': 0.631578947368421, 'BEL.NS': 0.7368421052631579, 'CIPLA.NS': 0.631578947368421, 'COALINDIA.NS': 0.7368421052631579, 'HCLTECH.NS': 0.8421052631578947, 'HDFCLIFE.NS': 0.7368421052631579, 'INDIGO.NS': 0.631578947368421, 'ITC.NS': 0.8421052631578947, 'M&M.NS': 0.7368421052631579, 'MAXHEALTH.NS': 0.6842105263157895, 'NESTLEIND.NS': 0.7894736842105263, 'POWERGRID.NS': 0.7368421052631579, 'SBILIFE.NS': 0.7894736842105263, 'TATACONSUM.NS': 0.7368421052631579, 'TATAMOTORS.NS': 0.7368421052631579, 'TATASTEEL.NS': 0.631578947368421, 'TECHM.NS': 0.7368421052631579, 'TITAN.NS': 0.8947368421052632, 'WIPRO.NS': 0.6842105263157895}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.6\n",
    "high_accuracy_symbols = {\n",
    "    symbol: acc for symbol, acc in accuracy_dict.items() if acc > threshold\n",
    "}\n",
    "\n",
    "print(high_accuracy_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f1505-561e-4195-bce8-63cf01dd746f",
   "metadata": {},
   "source": [
    "#### Below is an extra piece of code where i can just run it to check how accurate have I been today\n",
    "#### The below mentioned function is to get the return today and to check if my predicton is correct or not\n",
    "#### Note, call this function only after the trading day is over (preferably after some time its been over, depending on how fast yfinance updates its data) otherwise it will give return of yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f06026c9-c025-477c-a85f-cfd884bf67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today_return(symbol):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    today_data = ticker.history(period='2d').Close\n",
    "    today_return = (today_data[-1] / today_data[0]) - 1\n",
    "    \n",
    "    return today_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea7965-b5b3-4c72-8c47-c614ff47d069",
   "metadata": {},
   "source": [
    "#### Below i check the return and compare it to my prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78c29eff-04fa-4329-b473-1bcc2faef2f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for ADANIENT.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Prediction Wrong for AXISBANK.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Prediction correct for BEL.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction correct for CIPLA.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for COALINDIA.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for HCLTECH.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for HDFCLIFE.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Prediction correct for INDIGO.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Prediction correct for ITC.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction Wrong for M&M.NS\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for MAXHEALTH.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction correct for NESTLEIND.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Prediction correct for POWERGRID.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction correct for SBILIFE.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Prediction correct for TATACONSUM.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction Wrong for TATAMOTORS.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Prediction correct for TATASTEEL.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Prediction correct for TECHM.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction correct for TITAN.NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction Wrong for WIPRO.NS\n",
      "Our Accuracy for today is 0.8\n",
      "Our Total correct predictions are 16\n",
      "Total Companies in our Portfolio are 20\n",
      "Our Total Return for today is 0.0\n",
      "Predictions Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_10034/92847729.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  today_return = (today_data[-1] / today_data[0]) - 1\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().date()\n",
    "start_date = today - timedelta(days=50)\n",
    "end_date = today - timedelta(days=1)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_return = 0\n",
    "for symbol in high_accuracy_symbols :\n",
    "    total+=1\n",
    "    data = get_ticker_data(symbol, start_date, end_date)\n",
    "\n",
    "    if len(data) < 30:\n",
    "            print(f'Not Sufficient data for {symbol}')\n",
    "            continue\n",
    "    \n",
    "    data = data.tail(30)\n",
    "    input_np = np.array([data.values])\n",
    "    \n",
    "    model = load_model(f'model1_{symbol}/model.keras')\n",
    "    \n",
    "    prediction = model.predict(input_np)[0][0]\n",
    "    actual = get_today_return(symbol)\n",
    "    if int(actual > 0) == int(prediction > 0.5):\n",
    "        print(f'Prediction correct for {symbol}')\n",
    "        correct+=1\n",
    "        \n",
    "    else:\n",
    "        print(f'Prediction Wrong for {symbol}')\n",
    "        \n",
    "    total_return+=actual \n",
    "print('Our Accuracy for today is',correct / total)\n",
    "print('Our Total correct predictions are',correct)\n",
    "print('Total Companies in our Portfolio are',total)\n",
    "print('Our Total Return for today is',total_return)\n",
    "print('Predictions Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd22a8-ae54-4f0d-983f-87a99b2d7316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
